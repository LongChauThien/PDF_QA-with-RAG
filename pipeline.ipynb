{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from io import BytesIO\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "\n",
    "model_name = \"BAAI/bge-large-en\"\n",
    "# model_kwargs = {'device': 'cuda'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    # model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Store Created.......\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loader = PyPDFLoader(\"./backend/app/upload_files/572_qd_dhcntt29_09_2021_cvht_k2021.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=450,chunk_overlap=200)\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=250,chunk_overlap=10)\n",
    "\n",
    "vectorstore = Chroma(collection_name=\"split_parents\", embedding_function=embeddings,collection_metadata={\"hnsw:space\": \"cosine\"})\n",
    "\n",
    "store = InMemoryStore()\n",
    "print(\"Vector Store Created.......\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.add_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241m.\u001b[39mget_relevant_documents(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat is title of the document?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'retriever' is not defined"
     ]
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"what is title of the document?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = PyPDFLoader(\"./backend/app/upload_files/Identification_of_Gender_from_Facial_Features.pdf\")\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=450, chunk_overlap=30)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "vector_store2 = Chroma.from_documents(texts, embeddings, collection_metadata={\"hnsw:space\": \"cosine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_retriever = vector_store2.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=450, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(docs)\n",
    "bm25_retriever.k = 2\n",
    "\n",
    "\n",
    "retriever_ensemble = EnsembleRetriever(retrievers=[bm25_retriever, chroma_retriever], weights=[0.25, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever_ensemble.get_relevant_documents(\"what is main content?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 0, 'source': './backend/app/upload_files/Identification_of_Gender_from_Facial_Features.pdf'}, page_content='Copyright: ©  the author(s), publisher and licensee Technoscience Academy. This is an open -access article distributed under the \\nterms of the Creative Commons Attribution Non -Commercial License, which permits unrestricted non -commercial use, \\ndistribution, and reproducti on in any medium, provided the original work is properly cited  \\n International Journal of Scientific Research in Computer Science, Engineering and Information Technology'),\n",
       " Document(metadata={'page': 4, 'source': './backend/app/upload_files/Identification_of_Gender_from_Facial_Features.pdf'}, page_content='difference  of the second variable onto the first \\nvariable by translation and rotation of original axes \\nand projecting data onto new axes. The direction of \\nprojection is decided using eige nvalues and \\neigenvectors. So, the first few modified  features \\n(termed as Principal Components) are rich in \\ninformation, whereas the last features contain mostly \\nnoise with negligible information in them. This'),\n",
       " Document(metadata={'source': './backend/app/upload_files/Identification_of_Gender_from_Facial_Features.pdf', 'page': 5}, page_content=\"step.  \\n \\nChallenges  \\n \\nOne of the main challenges for classifying gender \\nusing  facial images is that the eff ect of the posture of \\nthe person, illumination and ground noise . While \\nneural networks are ready to learn representations, \\nthey're subject to certain spatial conditions of the \\ninput images. With the assistance of preprocessing, \\nthe proposed approach is in  a position to form all \\ninput images uniform. This helps in reliable\"),\n",
       " Document(metadata={'source': './backend/app/upload_files/Identification_of_Gender_from_Facial_Features.pdf', 'page': 5}, page_content='score we can understand the app select that model or \\nnot.at next we will use ROC and AUC but for that we \\nrequire probability. To overcome this drawback we \\nhave to set Probability=True in our model evolution  \\nstep.  \\n \\nChallenges  \\n \\nOne of the main challenges for classifying gender \\nusing  facial images is that the eff ect of the posture of \\nthe person, illumination and ground noise . While')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_to_return = [\n",
    "            {\n",
    "                'metadata': doc.metadata,\n",
    "                'page_content': doc.page_content\n",
    "            }\n",
    "            for doc in docs\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'metadata': {'page': 0,\n",
       "   'source': './backend/app/upload_files/Identification_of_Gender_from_Facial_Features.pdf'},\n",
       "  'page_content': 'Copyright: ©  the author(s), publisher and licensee Technoscience Academy. This is an open -access article distributed under the \\nterms of the Creative Commons Attribution Non -Commercial License, which permits unrestricted non -commercial use, \\ndistribution, and reproducti on in any medium, provided the original work is properly cited  \\n International Journal of Scientific Research in Computer Science, Engineering and Information Technology'},\n",
       " {'metadata': {'page': 4,\n",
       "   'source': './backend/app/upload_files/Identification_of_Gender_from_Facial_Features.pdf'},\n",
       "  'page_content': 'difference  of the second variable onto the first \\nvariable by translation and rotation of original axes \\nand projecting data onto new axes. The direction of \\nprojection is decided using eige nvalues and \\neigenvectors. So, the first few modified  features \\n(termed as Principal Components) are rich in \\ninformation, whereas the last features contain mostly \\nnoise with negligible information in them. This'},\n",
       " {'metadata': {'source': './backend/app/upload_files/Identification_of_Gender_from_Facial_Features.pdf',\n",
       "   'page': 5},\n",
       "  'page_content': \"step.  \\n \\nChallenges  \\n \\nOne of the main challenges for classifying gender \\nusing  facial images is that the eff ect of the posture of \\nthe person, illumination and ground noise . While \\nneural networks are ready to learn representations, \\nthey're subject to certain spatial conditions of the \\ninput images. With the assistance of preprocessing, \\nthe proposed approach is in  a position to form all \\ninput images uniform. This helps in reliable\"},\n",
       " {'metadata': {'source': './backend/app/upload_files/Identification_of_Gender_from_Facial_Features.pdf',\n",
       "   'page': 5},\n",
       "  'page_content': 'score we can understand the app select that model or \\nnot.at next we will use ROC and AUC but for that we \\nrequire probability. To overcome this drawback we \\nhave to set Probability=True in our model evolution  \\nstep.  \\n \\nChallenges  \\n \\nOne of the main challenges for classifying gender \\nusing  facial images is that the eff ect of the posture of \\nthe person, illumination and ground noise . While'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: The title of the document is \"ĐẠI HỌC QUốC GIA TP.HCM TRƯỜNG ĐẠI HỌC CÔNG NGHỆ THÔNG TIN CỘNG HòA XÃ HỘI CHỦ NGHĨA VIỆT NAM Độc lập \n",
      "-Ban hành kèm theo Quyết định số: 572 \n",
      "/QĐ-ĐHCNTT ngày 29 tháng 9 năm 2021\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "print(doc) #print all lines of doc using .splitlines() method\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = Ollama(model=\"phi\")\n",
    "prompt_template = \"\"\"Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=['context', 'question'])\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "\n",
    "try:\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever_ensemble, return_source_documents=True, chain_type_kwargs=chain_type_kwargs, verbose=True)\n",
    "    \n",
    "    def get_response(input):\n",
    "        query = input\n",
    "        response = qa(query)\n",
    "        # docs = vector_store.similarity_search_with_score(query)\n",
    "        result = 'Answer:' + response['result']\n",
    "        # +'\\n' + 'Similarity_score: '+ str(docs[0][1])\n",
    "        return result\n",
    "\n",
    "    print(get_response(\"what is title of the document?\"))\n",
    "\n",
    "except ConnectionRefusedError as e:\n",
    "    print(f\"ConnectionRefusedError: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Ollama' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CallbackManager\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstreaming_stdout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StreamingStdOutCallbackHandler\n\u001b[1;32m----> 4\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mOllama\u001b[49m(\n\u001b[0;32m      5\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama3\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback_manager\u001b[38;5;241m=\u001b[39mCallbackManager([StreamingStdOutCallbackHandler()])\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m llm(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe first man on the summit of Mount Everest, the highest peak on Earth, was ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Ollama' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "llm = Ollama(\n",
    "    model=\"llama3\", callback_manager=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    ")\n",
    "llm(\"The first man on the summit of Mount Everest, the highest peak on Earth, was ...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
